---
title: | 
  | Analyse de deux algorithmes de tableau maximum par comparaison
author:  "Manal Derghal, Khalil Ounis, {Taqwa Ben Romdhane}"
date: "lundi 7 avril 2025"
header-includes:
  - \usepackage[french]{babel}
output:
  pdf_document:
    keep_tex: yes
    toc: true
    number_sections: true  
urlcolor: blue
---

---
title: | 
  | Analyse des algorithmes de Maximum Subarray 1D
  |  M2 Data Science Algorithmique 
author:  "Khalil Ounis, Manal Derghal, Taqwa BenRomdhane"
date: "Lundi 7 avril 2025"
header-includes:
  - \usepackage[french]{babel}
output:
  pdf_document:
    keep_tex: yes
    toc: true
    number_sections: true  
urlcolor: blue
---

\noindent\hrulefill


# Description du problème et objectif

Le problème du Maximum Subarray 1D consiste à trouver la sous-séquence contiguë d'un tableau numérique dont la somme des éléments est maximale. Ce problème classique en algorithmique a des applications en analyse de données financières, bioinformatique et traitement du signal.

[La page Wikipedia du Maximum Subarray](https://en.wikipedia.org/wiki/Maximum_subarray_problem) présente plusieurs approches algorithmiques pour résoudre ce problème. Nous nous concentrons sur deux méthodes :

1. Algorithme naïf : complexité O(n²)
2. Algorithme de Kadane : complexité optimale O(n)

Nos objectifs sont :  
a. d'implémenter ces algorithmes en R et C++ et évaluer le gain de temps.  
b. de confirmer les complexités théoriques par des simulations intensives.

___ 

# Un premier exemple

Le package se télécharge ainsi :

```{r, eval=FALSE}
devtools::install_github("AMATERASU11/MaximumSubarray")
```

et ses fonctions sont rendues disponibles sur Rstudio ainsi :

```{r}
library(MaximumSubarray)
```

On simule un petit exemple d'un vecteur `v` de taille `100`

```{r}
set.seed(123)
v <- sample(-100:100, 50, replace = TRUE)
```

On teste les 4 algorithmes implémentés avec des noms explicites : 

- `max_subarray_sum_naive` 
- `max_subarray_sum_opt` 
- `max_subarray_sum_naive_Rcpp` 
- `max_subarray_sum_opt_Rcpp` 

Cela donne :

```{r}
v
max_subarray_sum_naive(v)
max_subarray_sum_naive_Rcpp(v)
max_subarray_sum_opt(v)
max_subarray_sum_opt_Rcpp(v)
```


___ 

# Comparaison R avec C++

On va faire des comparaisons pour les deux types d'algorithme en R et C++ pour quantifier leur différence de performance.

La fonction `one.simu.time` retourne le temps recherché, et `one.simu` sera utilisé par `microbenchmark`, on retourne le temps en ms

```{r}
library(microbenchmark)
set.seed(123)

one.simu.time <- function(n, func, data_type = "random") {
  if (data_type == "random") {
    v <- sample(-100:100, n, replace = TRUE)
  } else if (data_type == "all_negative") {
    v <- sample(-100:-1, n, replace = TRUE)
  } else if (data_type == "all_positive") {
    v <- sample(0:100, n, replace = TRUE)
  } else {
    stop("data_type inconnu")
  }

  if (func == "naive") {
    t <- microbenchmark(max_subarray_sum_naive(v), times = 1)$time / 1e6
  } else if (func == "naive_Rcpp") {
    t <- microbenchmark(max_subarray_sum_naive_Rcpp(v), times = 1)$time / 1e6
  } else if (func == "opt") {
    t <- microbenchmark(max_subarray_sum_opt(v), times = 1)$time / 1e6
  } else if (func == "opt_Rcpp") {
    t <- microbenchmark(max_subarray_sum_opt_Rcpp(v), times = 1)$time / 1e6
  } else {
    stop("fonction inconnue")
  }

  return(round(t, 2))
}


```

## Un essai

Sur un exemple, on obtient :

```{r}
set.seed(123)
n <- 10000
one.simu.time(n, func = "naive")
one.simu.time(n, func = "naive_Rcpp")
one.simu.time(n, func = "opt")
one.simu.time(n, func = "opt_Rcpp")
```


## Simulations avec répétitions

On reproduit ces comparaisons de manière plus robuste:

```{r first simu}
set.seed(123)
nbSimus <- 10

time1 <- rep(0, nbSimus); time2 <- rep(0, nbSimus);
time3 <- rep(0, nbSimus); time4 <- rep(0, nbSimus)

for(i in 1:nbSimus){time1[i] <- one.simu.time(n, func = "naive")}
for(i in 1:nbSimus){time2[i] <- one.simu.time(n, func = "naive_Rcpp")}
for(i in 1:nbSimus){time3[i] <- one.simu.time(n, func = "opt")}
for(i in 1:nbSimus){time4[i] <- one.simu.time(n, func = "opt_Rcpp")}
```

Gain C++ versus R

```{r}
mean(time1)/mean(time2)
mean(time3)/mean(time4)
```

Gain naive versus optimisé

```{r}
mean(time1)/mean(time3)
mean(time2)/mean(time4)
```

On recommence avec `n = 20000` seulement pour le gain avec C++ pour l'optimisé

```{r second simu}
set.seed(123)
n <- 20000
nbSimus <- 10
time3 <- rep(0, nbSimus); time4 <- rep(0, nbSimus)
for(i in 1:nbSimus){time3[i] <- one.simu.time(n, func = "opt")}
for(i in 1:nbSimus){time4[i] <- one.simu.time(n, func = "opt_Rcpp")}
median(time3)/median(time4)
```


**Conclusion:**

### Performances C++ vs R :

- Naïf : C++ 443× plus rapide 

- Kadane : C++ 102× plus rapide → 177× pour n=20k

### Efficacité algorithmique :

- Kadane 3 261× mieux que naïf en R, 754× en C++

- Confirme O(n²) naïf vs O(n) Kadane

### Recommandations :

- n > 1k : Toujours préférer Kadane

- n > 10k : Obligatoire d'utiliser Rcpp

- Très grands n : Seul Kadane+Rcpp reste viable

## Simulations avec `microbenchmark`

Vous avez besoin des packages `microbenchmark` et `ggplot2` pour exécuter les simulations et afficher les résultats (sous forme de diagrammes en violon). Nous comparons `naive_Rcpp` avec `opt_Rcpp` pour des tailles de données `n = 1000` et `n = 10000`.

```{r}
library(microbenchmark)
library(ggplot2)
library(dplyr)
```

```{r benchmark, echo = FALSE, warning=FALSE, message=FALSE}
set.seed(123)

benchmark_1d <- function(n) {
  v <- sample(-100:100, n, replace = TRUE)
  microbenchmark(
    Naif_Cpp = max_subarray_sum_naive_Rcpp(v),
    Kadane_Cpp = max_subarray_sum_opt_Rcpp(v),
    times = 50
  )
}

n_values <- c(100, 5000, 10000)
results_1d <- lapply(n_values, benchmark_1d)

# Visualisation
df_1d <- do.call(rbind, Map(cbind, results_1d, n = n_values))
ggplot(df_1d, aes(x = expr, y = time/1e6, fill = expr)) +
  geom_violin() +
  facet_wrap(~n, scales = "free") +
  labs(title = "Comparaison des algorithmes Maximum Subarray 1D",
       x = "Algorithm",
       y = "Temps (ms)") +
  theme_minimal()
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
df_1d %>%
  group_by(n, expr) %>%
  summarise(
    min_time = min(time) / 1e6,   # Convert nanoseconds to milliseconds
    q1_time = quantile(time, 0.25) / 1e6,
    median_time = median(time) / 1e6,
    mean_time = mean(time) / 1e6,
    q3_time = quantile(time, 0.75) / 1e6,
    max_time = max(time) / 1e6,
    .groups = "drop"
  )
```


___ 


# Evaluation de la complexité

Les vecteurs de longueurs `vector_n_naive` et `vector_n_kadane` (`n` dans les dataframes) sont choisis sur l'echelle logarithmique afin d'avoir un pas constant sur l'échelle logarithmique en abscisse pour la régression.

On réalise 10 répétitions pour chaque valeur de `n` et pour chaque algorithme. Les barres d'erreur sont placées en "mean +/- sd". 

```{r simu complexite, echo = FALSE, warning=FALSE, message=FALSE}
set.seed(123)

# Function to run benchmarking with mean and standard deviation
benchmark_subarray <- function(func_name, n_values, nbRep) {
  results <- sapply(n_values, function(n) {
    times <- replicate(nbRep, one.simu.time(n, func = func_name))  # Run simulations
    c(mean_time = mean(times), sd_time = sd(times))  # Return mean & std dev
  })
  
  # Convert results to a data frame
  data.frame(n = n_values, mean_time = results["mean_time",], sd_time = results["sd_time",])
}

# Parameters
nbSimus <- 20
nbRep <- 10

# Benchmark pour l'algorithme naïf
vector_n_naive <- exp(seq(log(5000), log(50000), length.out = nbSimus)) |> round()
res_Naive <- benchmark_subarray("naive_Rcpp", vector_n_naive, nbRep)

# Benchmark pour Kadane
vector_n_kadane <- exp(seq(log(400000), log(700000), length.out = nbSimus)) |> round()
res_Kadane <- benchmark_subarray("opt_Rcpp", vector_n_kadane, nbRep)

# Graphique log-log avec barres d'erreur
ggplot() +
  # Algorithme naïf
  geom_line(data = res_Naive, aes(x = n, y = mean_time, color = "Naïf Rcpp"), size = 1) +
  geom_errorbar(data = res_Naive, 
                aes(x = n, ymin = mean_time - sd_time, ymax = mean_time + sd_time, color = "Naïf Rcpp"), 
                width = 0.1, alpha = 0.5) +
  
  # Algorithme de Kadane
  geom_line(data = res_Kadane, aes(x = n, y = mean_time, color = "Kadane Rcpp"), size = 1) +
  geom_errorbar(data = res_Kadane, 
                aes(x = n, ymin = mean_time - sd_time, ymax = mean_time + sd_time, color = "Kadane Rcpp"), 
                width = 0.1, alpha = 0.5) +

  # Échelles logarithmiques
  scale_x_log10() +
  scale_y_log10() +
  
  # Labels & thème
  labs(title = "Performance des algorithmes Maximum Subarray (échelle log-log)",
       x = "Taille des données (échelle log)", 
       y = "Temps moyen d'exécution (ms, échelle log)",
       color = "Algorithm") +
  theme_minimal()

```

```{r}
# Affichage des résultats
res_Naive
res_Kadane
```

On vérifie la valeur du coefficient directeur pour les deux méthodes:

```{r, echo = FALSE, warning=FALSE, message=FALSE}
# Estimation de la complexité pour l'algorithme naïf
model_naive <- lm(log(res_Naive$mean_time) ~ log(res_Naive$n))
print(summary(model_naive)) 
cat("Exposant estimé (naïf):", coef(model_naive)[2], "\n")
```


```{r, echo = FALSE, warning=FALSE, message=FALSE}
# Estimation de la complexité pour Kadane
model_kadane <- lm(log(res_Kadane$mean_time) ~ log(res_Kadane$n))
print(summary(model_kadane)) 
cat("Exposant estimé (Kadane):", coef(model_kadane)[2], "\n")
```

Les coefficients directeurs trouvés sont bien ceux que l'on attendait. La valeur 2 pour la méthode naïve et 1 pour l'algorithme de Kadane


___ 


# Cas particulier des données presques toutes négatives ou toutes positives

- cas 1 : 95% de valeurs négatives, 5% positives
- cas 2 : 95% de valeurs positives, 5% négatives


```{r benchmark2, echo = FALSE, warning=FALSE, message=FALSE}
# Fonction de benchmark pour données majoritairement négatives/positives
benchmark_subarray_biased <- function(n, case, ratio = 0.95) {
  if (case == "mostly_negative") {
    # 95% de valeurs négatives, 5% positives
    v <- c(
      sample(-100:-1, round(n * ratio), replace = TRUE),
      sample(1:100, n - round(n * ratio), replace = TRUE)
    )
  } else if (case == "mostly_positive") {
    # 95% de valeurs positives, 5% négatives
    v <- c(
      sample(1:100, round(n * ratio), replace = TRUE),
      sample(-100:-1, n - round(n * ratio), replace = TRUE)
    )
  } else {
    # Cas aléatoire, valeurs dans l'intervalle [-100, 100]
    v <- sample(-100:100, n, replace = TRUE)
  }
  
  # Mélange aléatoire des valeurs
  v <- sample(v)
  
  microbenchmark(
    Naif = max_subarray_sum_naive_Rcpp(v),
    Kadane = max_subarray_sum_opt_Rcpp(v),
    times = 50,
    unit = "ms"
  )
}

# Exemple d'utilisation
n_values <- c(1000, 10000)
cases <- c("mostly_negative", "mostly_positive", "random")

# Génération des résultats
results <- expand.grid(n = n_values, case = cases) |>
  rowwise() |>
  mutate(
    bm = list(benchmark_subarray_biased(n, case)),
    data = list(
      data.frame(
        n = n,
        case = case,
        algo = bm$expr,
        time = bm$time / 1e6  # Conversion en ms
      )
    )
  ) |>
  pull(data) |>
  bind_rows()

# Visualisation par violon
ggplot(results, aes(x = case, y = time, fill = algo)) +
  geom_violin(alpha = 0.7, trim = FALSE) +
  facet_wrap(~n, scales = "free_y", labeller = labeller(n = function(x) paste("n =", x))) +
  scale_y_log10() +  # Échelle log pour mieux voir les différences
  labs(
    title = "Comparaison des algorithmes Maximum Subarray",
    subtitle = "Performance sur différents cas de données",
    x = "Type de données d'entrée",
    y = "Temps d'exécution (ms, échelle log)",
    fill = "Algorithme"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
library(tidyr)

# Statistiques détaillées
stats_results <- results |>
  group_by(n, case, algo) |>
  summarise(
    min = min(time),
    q1 = quantile(time, 0.25),
    median = median(time),
    mean = mean(time),
    q3 = quantile(time, 0.75),
    max = max(time),
    .groups = "drop"
  ) |>
  arrange(n, case, algo)

# Affichage des stats
print(stats_results)
```

```{r}
library(dplyr)
library(tidyr)

gain_comparison <- stats_results %>%
  group_by(n, case) %>%
  summarise(
    gain = median[algo == "Naif"]/median[algo == "Kadane"],
    .groups = "drop"
  )

print(gain_comparison)
```
```{r}
gain_plot <- gain_comparison %>%
  ggplot(aes(x = case, y = gain, fill = factor(n))) +
  geom_col(position = position_dodge(preserve = "single")) +
  geom_text(aes(label = round(gain, 1)), 
            position = position_dodge(width = 0.9),
            vjust = -0.5) +
  labs(
    title = "Gain de performance de Kadane vs Naïf",
    x = "Type de données",
    y = "Facteur d'accélération",
    fill = "Taille (n)"
  ) +
  theme_minimal() +
  scale_fill_brewer(palette = "Pastel1")

print(gain_plot)
```


Ces résultats montrent que les algorithmes sont plus efficaces sur des données avec une structure, comme celles qui sont majoritairement positives ou négatives, par rapport aux données complètement aléatoires.
