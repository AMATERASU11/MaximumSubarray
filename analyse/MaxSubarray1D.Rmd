---
title: | 
  | Analyse de deux algorithmes de tableau maximum par comparaison
author: "Manal Derghal, Khalil Ounis, Taqwa Ben  Romdhane"
date: "lundi 7 avril 2025"
header-includes:
  - \usepackage[french]{babel}
output:
  pdf_document:
    keep_tex: yes
    toc: true
    number_sections: true  
urlcolor: blue
---

---
title: | 
  | Analyse des algorithmes de Maximum Subarray 1D
  |  M2 Data Science Algorithmique 
author:  "Manal Derghal, Khalil Ounis, Taqwa Ben Romdhane"
date: "Lundi 7 avril 2025"
header-includes:
  - \usepackage[french]{babel}
output:
  pdf_document:
    keep_tex: yes
    toc: true
    number_sections: true  
urlcolor: blue
---

\noindent\hrulefill

# Description du problème et objectif

Le problème du Maximum Subarray 1D consiste à trouver la sous-séquence contiguë d'un tableau numérique dont la somme des éléments est maximale. Ce problème classique en algorithmique a des applications en analyse de données financières, bioinformatique et traitement du signal.

[La page Wikipedia du Maximum Subarray](https://en.wikipedia.org/wiki/Maximum_subarray_problem) présente plusieurs approches algorithmiques pour résoudre ce problème. Nous nous concentrons sur deux méthodes :

1.  Algorithme naïf : complexité O(n²)
2.  Algorithme de Kadane : complexité optimale O(n)

Nos objectifs sont :\
a. d'implémenter ces algorithmes en R et C++ et évaluer le gain de temps.\
b. de confirmer les complexités théoriques par des simulations intensives.

------------------------------------------------------------------------

# Un premier exemple

Le package se télécharge ainsi :

```{r, eval=FALSE}
devtools::install_github("AMATERASU11/MaximumSubarray")
```

et ses fonctions sont rendues disponibles sur Rstudio ainsi :

```{r}
library(MaximumSubarray)
```

On simule un petit exemple d'un vecteur `v` de taille `100`

```{r}
set.seed(123)
v <- sample(-100:100, 100, replace = TRUE)
```

On teste les 4 algorithmes implémentés avec des noms explicites :

-   `max_subarray_sum_naive`
-   `max_subarray_sum_opt`
-   `max_subarray_sum_naive_Rcpp`
-   `max_subarray_sum_opt_Rcpp`

Cela donne :

```{r}
v
max_subarray_sum_naive(v)
max_subarray_sum_naive_Rcpp(v)
max_subarray_sum_opt(v)
max_subarray_sum_opt_Rcpp(v)
```

------------------------------------------------------------------------

# Comparaison R avec C++

On va faire des comparaisons pour les deux types d'algorithme en R et C++ pour quantifier leur différence de performance.

La fonction `one.simu.time` retourne le temps recherché, et `one.simu` sera utilisé par `microbenchmark`, on retourne le temps en ms

```{r}
library(microbenchmark)

one.simu.time <- function(n, func) {
  
  v <- sample(-100:100, n, replace = TRUE)

  if (func == "Naive1D") {
    t <- microbenchmark(max_subarray_sum_naive(v), times = 1)$time / 1e6
  } else if (func == "Naive1D_cpp") {
    t <- microbenchmark(max_subarray_sum_naive_Rcpp(v), times = 1)$time / 1e6
  } else if (func == "Kadane1D") {
    t <- microbenchmark(max_subarray_sum_opt(v), times = 1)$time / 1e6
  } else if (func == "Kadane1D_cpp") {
    t <- microbenchmark(max_subarray_sum_opt_Rcpp(v), times = 1)$time / 1e6
  } else {
    stop("fonction inconnue")
  }

  return(round(t, 2))
}


```

## Un essai

### Temps d'exécution en R

Sur un exemple, on obtient :

```{r}
# Simulation sur une matrice de taille n
n <- 10000

# Exécuter la simulation
res_naive <- one.simu.time(n,"Naive1D")
res_kadane <- one.simu.time(n, "Kadane1D")

# Afficher les résultats
cat("time_naive:", res_naive,"ms\n")
cat("time_kadane:", res_kadane, "ms")
```

### Temps d'exécution en C++

sur un vecteur de taille 10000 on obtient les résultats suivants :

```{r}
# Simulation sur une matrice de taille n
n <- 10000

res_naive_cpp <- one.simu.time(n,"Naive1D_cpp")
res_Kadane_cpp <- one.simu.time(n,"Kadane1D_cpp")

# Afficher les résultats
cat("time_naive_cpp:" ,res_naive_cpp,"ms\n")
cat("time_kadane_cpp:",res_Kadane_cpp, "ms")
```


## Simulations avec répétitions

On reproduit ces comparaisons de manière plus robuste:

```{r first simu}
nbSimus <- 10

time_naive <- rep(0, nbSimus); time_naive_cpp <- rep(0, nbSimus);
time_kadane <- rep(0, nbSimus); time_kadane_cpp <- rep(0, nbSimus)

for(i in 1:nbSimus){time_naive[i] <- one.simu.time(n, func = "Naive1D")}
for(i in 1:nbSimus){time_naive_cpp[i] <- one.simu.time(n, func = "Naive1D_cpp")}
for(i in 1:nbSimus){time_kadane[i] <- one.simu.time(n, func = "Kadane1D")}
for(i in 1:nbSimus){time_kadane_cpp[i] <- one.simu.time(n, func = "Kadane1D_cpp")}
```

### Gain R versus C++

```{r}
naive_speedup_cpp <- mean(time_naive) / mean(time_naive_cpp)
kadane_speedup_cpp <- mean(time_kadane) / mean(time_kadane_cpp)
cat("le gain R vs cpp pour naif:", round(naive_speedup_cpp,2),"ms\n")
cat("le gain R vs cpp pour Kadane:", round(kadane_speedup_cpp,2),"ms\n")
```

### Gain Naif Versus Kadane en R et C++

```{r}
kadane_vs_naive_R <- mean(time_naive) / mean(time_kadane)
kadane_vs_naive_Rcpp <- mean(time_naive_cpp) / mean(time_kadane_cpp)
cat("le gain naif vs Kadane en R est:",round(kadane_vs_naive_R,2), "ms\n")
cat("le gain cpp est:",round(kadane_vs_naive_Rcpp,2), "ms\n")
```

On recommence avec `n = 20000` seulement pour le gain avec C++ pour Kadane

```{r second simu}
set.seed(123)
n <- 20000
nbSimus <- 10
time_kadane <- rep(0, nbSimus); time_kadane_cpp <- rep(0, nbSimus)
for(i in 1:nbSimus){time_kadane[i] <- one.simu.time(n, func = "Kadane1D")}
for(i in 1:nbSimus){time_kadane_cpp[i] <- one.simu.time(n, func = "Kadane1D_cpp")}
median_kadane_R_vs_Rcpp <- median(time_kadane) / median(time_kadane_cpp)
cat("le gain Kadane en R vs Kadane en C++ est:",round(median_kadane_R_vs_Rcpp,2), "ms\n")
```

**Conclusion:**

### Performances C++ vs R :

-   Naïf : C++ `r round(naive_speedup_cpp)`× plus rapide\
-   Kadane : C++ `r round(kadane_speedup_cpp)`× plus rapide → `r round(median_kadane_R_vs_Rcpp)`× pour n=20k

### Efficacité algorithmique :

-   Kadane `r round(kadane_vs_naive_R)`× mieux que naïf en R\

-   Kadane `r round(kadane_vs_naive_Rcpp)`× mieux que naïf en C++


## Simulations avec `microbenchmark`

Vous avez besoin des packages `microbenchmark` et `ggplot2` pour exécuter les simulations et afficher les résultats (sous forme de diagrammes en violon). Nous comparons `naive_Rcpp` avec `opt_Rcpp` pour des tailles de données `n = 1000`, `n = 5000` et `n = 10000`.


```{r benchmark, echo = FALSE, warning=FALSE, message=FALSE}
set.seed(123)

library(microbenchmark)
library(ggplot2)
library(dplyr)

benchmark_1d <- function(n) {
  v <- sample(-100:100, n, replace = TRUE)
  microbenchmark(
    Naif1D_Cpp = max_subarray_sum_naive_Rcpp(v),
    Kadane1D_Cpp = max_subarray_sum_opt_Rcpp(v),
    times = 50
  )
}

n_values <- c(100, 5000, 10000)
results_1d <- lapply(n_values, benchmark_1d)

# Visualisation
df_1d <- do.call(rbind, Map(cbind, results_1d, n = n_values))
ggplot(df_1d, aes(x = expr, y = time/1e6, fill = expr)) +
  scale_y_log10() +
  geom_violin() +
  facet_wrap(~n, scales = "free") +
  labs(title = "Comparaison des algorithmes Maximum Subarray 1D",
       x = "Algorithm",
       y = "Temps (ms)") +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 60, vjust = 1, hjust = 1))

```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
df_1d %>%
  group_by(n, expr) %>%
  summarise(
    min_time = min(time) / 1e6,   # Convert nanoseconds to milliseconds
    q1_time = quantile(time, 0.25) / 1e6,
    median_time = median(time) / 1e6,
    mean_time = mean(time) / 1e6,
    q3_time = quantile(time, 0.75) / 1e6,
    max_time = max(time) / 1e6,
    .groups = "drop"
  )
```

------------------------------------------------------------------------

# Evaluation de la complexité

Les vecteurs de longueurs `vector_n_naive` et `vector_n_kadane` (`n` dans les dataframes) sont choisis sur l'echelle logarithmique afin d'avoir un pas constant sur l'échelle logarithmique en abscisse pour la régression.

On réalise 10 répétitions pour chaque valeur de `n` et pour chaque algorithme. Les barres d'erreur sont placées en "mean +/- sd".

```{r simu complexite, echo = FALSE, warning=FALSE, message=FALSE}
set.seed(123)

# Fonction pour exécuter les benchmarks sur les algorithmes 1D
benchmark_subarray <- function(func_name, n_values, nbRep) {
  results <- sapply(n_values, function(n) {
    times <- replicate(nbRep, one.simu.time(n, func = func_name))  # Run simulations
    c(mean_time = mean(times), sd_time = sd(times))  # Return mean & std dev
  })
  
  # Convert results to a data frame
  data.frame(n = n_values, mean_time = results["mean_time",], sd_time = results["sd_time",])
}

# Parameters
nbSimus <- 20
nbRep <- 10

# Benchmark pour l'algorithme naïf
vector_n_naive <- exp(seq(log(5000), log(50000), length.out = nbSimus)) |> round()
res_Naive <- benchmark_subarray("Naive1D_cpp", vector_n_naive, nbRep)

# Benchmark pour Kadane
vector_n_kadane <- exp(seq(log(200000), log(600000), length.out = nbSimus)) |> round()
res_Kadane <- benchmark_subarray("Kadane1D_cpp", vector_n_kadane, nbRep)

# Graphique log-log avec barres d'erreur
ggplot() +
  # Algorithme naïf
  geom_line(data = res_Naive, aes(x = n, y = mean_time, color = "Naïf Rcpp"), size = 1) +
  geom_errorbar(data = res_Naive, 
                aes(x = n, ymin = mean_time - sd_time, ymax = mean_time + sd_time, color = "Naïf Rcpp"), 
                width = 0.1, alpha = 0.5) +
  
  # Algorithme de Kadane
  geom_line(data = res_Kadane, aes(x = n, y = mean_time, color = "Kadane Rcpp"), size = 1) +
  geom_errorbar(data = res_Kadane, 
                aes(x = n, ymin = mean_time - sd_time, ymax = mean_time + sd_time, color = "Kadane Rcpp"), 
                width = 0.1, alpha = 0.5) +

  # Échelles logarithmiques
  scale_x_log10() +
  scale_y_log10() +
  
  # Labels & thème
  labs(title = "Performance des algorithmes Maximum Subarray (échelle log-log)",
       x = "Taille des données (échelle log)", 
       y = "Temps moyen d'exécution (ms, échelle log)",
       color = "Algorithm") +
  theme_minimal()

```

```{r}
# Affichage des résultats
cat("Les résultats pour la solution naïve:\n")
res_Naive
cat("Les résultats pour la solution optimale:\n")
res_Kadane
```

On vérifie la valeur du coefficient directeur pour les deux méthodes:

```{r, echo = FALSE, warning=FALSE, message=FALSE}
# Estimation de la complexité pour l'algorithme naïf
model_naive <- lm(log(res_Naive$mean_time) ~ log(res_Naive$n))
print(summary(model_naive)) 
cat("Exposant estimé (naïf):", coef(model_naive)[2], "\n")
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
# Estimation de la complexité pour Kadane
model_kadane <- lm(log(res_Kadane$mean_time) ~ log(res_Kadane$n))
print(summary(model_kadane)) 
cat("Exposant estimé (Kadane):", coef(model_kadane)[2], "\n")
```

Les coefficients directeurs trouvés sont bien ceux que l'on attendait. La valeur 2 pour la méthode naïve et 1 pour l'algorithme de Kadane

------------------------------------------------------------------------

# Cas particulier des données presques triées

On considère des données triées avec 5% de valeurs échangées au hasard.

Sur un exemple cela donne : 
```{r}
v <- 1:100
n_swap <- floor(0.05 * length(v))
swap_indices <- sample(length(v), n_swap)
v[swap_indices] <- sample(v[swap_indices])
v
```


```{r}

# Fonctions de simulation
one.simu <- function(n, func) {
  v <- sample(-100:100, n, replace = TRUE)
  if (func == "Naive1D_cpp") return(max_subarray_sum_naive_Rcpp(v))
  if (func == "Kadane1D_cpp") return(max_subarray_sum_opt_Rcpp(v))
}

one.simu2 <- function(n, func) {
  v <- 1:n
  n_swap <- floor(0.05 * n)
  swap_indices <- sample(n, n_swap)
  v[swap_indices] <- sample(v[swap_indices])
  if (func == "Naive1D_cpp") return(max_subarray_sum_naive_Rcpp(v))
  if (func == "Kadane1D_cpp") return(max_subarray_sum_opt_Rcpp(v))
}
```


```{r benchmark2, echo = FALSE, warning=FALSE, message=FALSE}
library(ggplot2)

# Benchmark
benchmark_subarray <- function(n, times = 50) {
  microbenchmark(
    naive_random = one.simu(n, "Naive1D_cpp"),
    kadane_random = one.simu(n, "Kadane1D_cpp"),
    naive_sorted = one.simu2(n, "Naive1D_cpp"),
    kadane_sorted = one.simu2(n, "Kadane1D_cpp"),
    times = times
  )
}

# Exécution pour différentes tailles
n_values <- c(1000, 10000)
results <- lapply(n_values, benchmark_subarray)

# Combine results into a single dataframe with n as an identifier
df_results <- do.call(rbind, Map(cbind, results, n = n_values))
# Plot with better aesthetics
ggplot(df_results, aes(x = expr, y = time / 1e6, fill = expr)) +
  geom_violin(alpha = 0.7) +
  scale_y_log10()+
  facet_wrap(~n, scales = "free") +
  labs(title = "Subarray Algorithm in Rcpp Benchmark",
       x = "Subarray Algorithm",
       y = "Execution Time (ms)",
       fill = "Algorithm") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 60, vjust = 1, hjust = 1))

```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
library(dplyr)
df_results %>%
  group_by(n, expr) %>%
  summarise(
    min_time = min(time) / 1e6,   # Convert nanoseconds to milliseconds
    q1_time = quantile(time, 0.25) / 1e6,
    median_time = median(time) / 1e6,
    mean_time = mean(time) / 1e6,
    q3_time = quantile(time, 0.75) / 1e6,
    max_time = max(time) / 1e6,
    .groups = "drop"
  ) %>%
  mutate(type = ifelse(grepl("sorted", expr), "sorted", "random")) %>%
  mutate(algo = ifelse(grepl("naive", expr), "naive", "kadane"))
```
Pour n = 1000, le temps d'exécution est plus rapide que pour n = 10000. Kadane est toujours plus rapide que Naïf, avec un écart plus important à n = 10000. Lorsque les tableaux sont triés, Naïf et Kadane sont beaucoup plus rapides, avec un écart réduit entre les deux.


# Cas particulier des données presques toutes positives

On considère un vecteur contenant des valeurs positives, avec 5% de valeurs négatives insérées aléatoirement dans le vecteur.

Sur un exemple cela donne : 


```{r}
set.seed(123)

# Vecteur de base : valeurs positives de 1 à 100
v_mostly_pos <- sample(1:100)

# Introduire 5% de valeurs négatives aléatoires
n_neg <- floor(0.05 * length(v_mostly_pos))  # 5% de négatifs
neg_indices <- sample(length(v_mostly_pos), n_neg)

# Remplacer ces valeurs par des valeurs négatives aléatoires
v_mostly_pos[neg_indices] <- -sample(1:100, n_neg)

# Affichage du vecteur
v_mostly_pos
```

```{r}

# Fonctions de simulation
one.simu <- function(n, func) {
  v <- sample(-100:100, n, replace = TRUE)
  if (func == "Naive1D_cpp") return(max_subarray_sum_naive_Rcpp(v))
  if (func == "Kadane1D_cpp") return(max_subarray_sum_opt_Rcpp(v))
}

one.simu2 <- function(n, func) {
  v_mostly_pos <- sample(1:100)
  n_neg <- floor(0.05 * length(v_mostly_pos))
  neg_indices <- sample(length(v_mostly_pos), n_neg)
  v_mostly_pos[neg_indices] <- -sample(1:100, n_neg)
  if (func == "Naive1D_cpp") return(max_subarray_sum_naive_Rcpp(v_mostly_pos))
  if (func == "Kadane1D_cpp") return(max_subarray_sum_opt_Rcpp(v_mostly_pos))
}
```


```{r benchmark3, echo = FALSE, warning=FALSE, message=FALSE}
library(ggplot2)

# Benchmark
benchmark_subarray <- function(n, times = 50) {
  microbenchmark(
    naive_random = one.simu(n, "Naive1D_cpp"),
    kadane_random = one.simu(n, "Kadane1D_cpp"),
    naive_most_pos = one.simu2(n, "Naive1D_cpp"),
    kadane_most_pos = one.simu2(n, "Kadane1D_cpp"),
    times = times
  )
}

# Exécution pour différentes tailles
n_values <- c(1000, 10000)
results <- lapply(n_values, benchmark_subarray)

# Combine results into a single dataframe with n as an identifier
df_results <- do.call(rbind, Map(cbind, results, n = n_values))

ggplot(df_results, aes(x = expr, y = time / 1e6, fill = expr)) +
  geom_violin(alpha = 0.7) +
  scale_y_log10() +
  facet_wrap(~n, scales = "free") +
  labs(title = "Subarray Algorithm in Rcpp Benchmark",
       x = "Subarray Algorithm",
       y = "Execution Time (ms)",
       fill = "Algorithm") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 60, vjust = 1, hjust = 1))
```

# Cas particulier des données presques toutes negatives

On considère un vecteur contenant des valeurs négatives, avec 5% de valeurs positives insérées aléatoirement dans le vecteur.

Sur un exemple cela donne : 


```{r}
set.seed(123)

# Vecteur de base : valeurs négatives de -1 à -100
v_mostly_neg <- -sample(1:100)

# Introduire 5% de valeurs positives aléatoires
n_pos <- floor(0.05 * length(v_mostly_neg))  # 5% de positifs
pos_indices <- sample(length(v_mostly_neg), n_pos)

# Remplacer ces valeurs par des valeurs positives aléatoires
v_mostly_neg[pos_indices] <- sample(1:100, n_pos)

# Affichage du vecteur
v_mostly_neg

```

```{r}

# Fonctions de simulation
one.simu <- function(n, func) {
  v <- sample(-100:100, n, replace = TRUE)
  if (func == "Naive1D_cpp") return(max_subarray_sum_naive_Rcpp(v))
  if (func == "Kadane1D_cpp") return(max_subarray_sum_opt_Rcpp(v))
}

one.simu2 <- function(n, func) {

  v_mostly_neg <- -sample(1:100)
  n_pos <- floor(0.05 * length(v_mostly_neg))
  pos_indices <- sample(length(v_mostly_neg), n_pos)
  v_mostly_neg[pos_indices] <- sample(1:100, n_pos)
  if (func == "Naive1D_cpp") return(max_subarray_sum_naive_Rcpp(v_mostly_neg ))
  if (func == "Kadane1D_cpp") return(max_subarray_sum_opt_Rcpp(v_mostly_neg ))
}
```


```{r benchmark4, echo = FALSE, warning=FALSE, message=FALSE}
library(ggplot2)

# Benchmark
benchmark_subarray <- function(n, times = 50) {
  microbenchmark(
    naive_random = one.simu(n, "Naive1D_cpp"),
    kadane_random = one.simu(n, "Kadane1D_cpp"),
    naive_most_neg = one.simu2(n, "Naive1D_cpp"),
    kadane_most_neg = one.simu2(n, "Kadane1D_cpp"),
    times = times
  )
}

# Exécution pour différentes tailles
n_values <- c(1000, 10000)
results <- lapply(n_values, benchmark_subarray)

df_results <- do.call(rbind, Map(cbind, results, n = n_values))

ggplot(df_results, aes(x = expr, y = time / 1e6, fill = expr)) +
  geom_violin(alpha = 0.7) +
  scale_y_log10() +
  facet_wrap(~n, scales = "free") +
  labs(title = "Subarray Algorithm in Rcpp Benchmark",
       x = "Subarray Algorithm",
       y = "Execution Time (ms)",
       fill = "Algorithm") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 60, vjust = 1, hjust = 1))

```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
library(dplyr)
df_results %>%
  group_by(n, expr) %>%
  summarise(
    min_time = min(time) / 1e6,   # Convert nanoseconds to milliseconds
    q1_time = quantile(time, 0.25) / 1e6,
    median_time = median(time) / 1e6,
    mean_time = mean(time) / 1e6,
    q3_time = quantile(time, 0.75) / 1e6,
    max_time = max(time) / 1e6,
    .groups = "drop"
  ) %>%
  mutate(type = ifelse(grepl("mostly_neg", expr), "mostly_neg", "random")) %>%
  mutate(algo = ifelse(grepl("naive", expr), "naive", "kadane"))
```
Pour n = 1000, le temps d'exécution est plus rapide que pour n = 10000. Kadane est toujours plus rapide que Naïf, avec un écart plus important à n = 10000. Lorsque les tableaux sont presques toutes négatif, Naïf et Kadane sont beaucoup plus rapides, avec un écart réduit entre les deux.

