---
title: | 
  | Analyse de deux algorithmes de tableau maximum par comparaison
author:  "Manal Derghal, Khalil Ounis, Taqwa Ben Romdhane"
date: "lundi 7 avril 2025"
header-includes:
  - \usepackage[french]{babel}
output:
  pdf_document:
    keep_tex: yes
    toc: true
    number_sections: true  
urlcolor: blue
---

\noindent\hrulefill


# Description du problème et objectif

---
title: | 
  | Analyse des algorithmes de Maximum Subarray 1D
  | ![](Images/logo_lamme.png){width=1in}  ![](Images/logo_UEVE.png){width=1.7in}
  |  M2 Data Science Algorithmique 
author:  "Khalil Ounis, Manal Derghal, Taqwa BenRomdhane"
date: "jeudi 27 mars 2025"
header-includes:
  - \usepackage[french]{babel}
output:
  pdf_document:
    keep_tex: yes
    toc: true
    number_sections: true  
urlcolor: blue
---

\noindent\hrulefill


# Description du problème et objectif

Le problème du Maximum Subarray 1D consiste à trouver la sous-séquence contiguë d'un tableau numérique dont la somme des éléments est maximale. Ce problème classique en algorithmique a des applications en analyse de données financières, bioinformatique et traitement du signal.

[La page Wikipedia du Maximum Subarray](https://en.wikipedia.org/wiki/Maximum_subarray_problem) présente plusieurs approches algorithmiques pour résoudre ce problème. Nous nous concentrons sur deux méthodes :

1. Algorithme naïf : complexité O(n²)
2. Algorithme de Kadane : complexité optimale O(n)

Nos objectifs sont :
a) d'implémenter ces algorithmes en R et C++ et évaluer le gain de temps ;
b) de confirmer les complexités théoriques par des simulations intensives.

___ 

# Un premier exemple

Le package se télécharge ainsi :

```{r, eval=FALSE}
devtools::install_github("AMATERASU11/MaximumSubarray")
```

et ses fonctions sont rendues disponibles sur Rstudio ainsi :

```{r}
library(MaximumSubarray)
```

On simule un petit exemple d'un vecteur `v` de taille `100`

```{r}
set.seed(123)
v <- sample(-100:100, 50, replace = TRUE)
```

On teste les 4 algorithmes implémentés avec des noms explicites : 

- `max_subarray_sum_naive` 
- `max_subarray_sum_opt` 
- `max_subarray_sum_naive_Rcpp` 
- `max_subarray_sum_opt_Rcpp` 

Cela donne :

```{r}
v
max_subarray_sum_naive(v)
max_subarray_sum_naive_Rcpp(v)
max_subarray_sum_opt(v)
max_subarray_sum_opt_Rcpp(v)
```


___ 

# Comparaison R avec C++

On va faire des comparaisons pour les deux types d'algorithme en R et C++ pour quantifier leur différence de performance.

La fonction `one.simu.time` retourne le temps recherché, et `one.simu` sera utilisé par `microbenchmark`, on retourne le temps en ms

```{r}
library(microbenchmark)

one.simu.time <- function(n, func, data_type = "random") {
  if (data_type == "random") {
    v <- sample(-100:100, n, replace = TRUE)
  } else if (data_type == "all_negative") {
    v <- runif(n, -100, -1)
  } else { # single_positive
    v <- runif(n, -100, -1)
    v[sample(n, 1)] <- runif(1, 1, 100)
  }

  if (func == "naive") {
    t <- microbenchmark(max_subarray_sum_naive(v), times = 1)$time / 1e6
  }
  if (func == "naive_Rcpp") {
    t <- microbenchmark(max_subarray_sum_naive_Rcpp(v), times = 1)$time / 1e6
  }
  if (func == "opt") {
    t <- microbenchmark(max_subarray_sum_opt(v), times = 1)$time / 1e6
  }
  if (func == "opt_Rcpp") {
    t <- microbenchmark(max_subarray_sum_opt_Rcpp(v), times = 1)$time / 1e6
  }

  # Arrondi à 2 décimales
  t <- round(t, 2)

  return(t)
}

```

## Un essai

Sur un exemple, on obtient :

```{r}
n <- 10000
one.simu.time(n, func = "naive")
one.simu.time(n, func = "naive_Rcpp")
one.simu.time(n, func = "opt")
one.simu.time(n, func = "opt_Rcpp")
```


## Simulations avec répétitions

On reproduit ces comparaisons de manière plus robuste:

```{r first simu}
nbSimus <- 10

time1 <- rep(0, nbSimus); time2 <- rep(0, nbSimus);
time3 <- rep(0, nbSimus); time4 <- rep(0, nbSimus)

for(i in 1:nbSimus){time1[i] <- one.simu.time(n, func = "naive")}
for(i in 1:nbSimus){time2[i] <- one.simu.time(n, func = "naive_Rcpp")}
for(i in 1:nbSimus){time3[i] <- one.simu.time(n, func = "opt")}
for(i in 1:nbSimus){time4[i] <- one.simu.time(n, func = "opt_Rcpp")}
```

Gain C++ versus R

```{r}

mean(time1)/mean(time2)
mean(time3)/mean(time4)
```

Gain naive versus optimisé

```{r}
mean(time1)/mean(time3)
mean(time2)/mean(time4)
```

On recommence avec `n = 20000` seulement pour le gain avec C++ pour l'optimisé

```{r second simu}
n <- 20000
nbSimus <- 10
time3 <- rep(0, nbSimus); time4 <- rep(0, nbSimus)
for(i in 1:nbSimus){time3[i] <- one.simu.time(n, func = "opt")}
for(i in 1:nbSimus){time4[i] <- one.simu.time(n, func = "opt_Rcpp")}
median(time3)/median(time4)
```


**Conclusion:**

### Performances C++ vs R :

- Naïf : C++ 523× plus rapide (26 ms vs 14 768 ms)

- Kadane : C++ 66× plus rapide (0.06 ms vs 3.69 ms) → 101× pour n=20k

### Efficacité algorithmique :

- Kadane 3 600× mieux que naïf en R, 460× en C++

- Confirme O(n²) naïf vs O(n) Kadane

### Recommandations :

- n > 1k : Toujours préférer Kadane

- n > 10k : Obligatoire d'utiliser Rcpp

- Très grands n : Seul Kadane+Rcpp reste viable

## Simulations avec `microbenchmark`

Vous avez besoin des packages `microbenchmark` et `ggplot2` pour exécuter les simulations et afficher les résultats (sous forme de diagrammes en violon). Nous comparons `naive_Rcpp` avec `opt_Rcpp` pour des tailles de données `n = 1000` et `n = 10000`.

```{r}
library(microbenchmark)
library(ggplot2)
```

```{r benchmark, echo = FALSE, warning=FALSE, message=FALSE}
library(microbenchmark)
library(ggplot2)

benchmark_1d <- function(n) {
  v <- sample(-100:100, n, replace = TRUE)
  microbenchmark(
    Naif_Cpp = max_subarray_sum_naive_Rcpp(v),
    Kadane_Cpp = max_subarray_sum_opt_Rcpp(v),
    times = 20
  )
}

n_values <- c(100, 5000, 10000)
results_1d <- lapply(n_values, benchmark_1d)

# Visualisation
df_1d <- do.call(rbind, Map(cbind, results_1d, n = n_values))
ggplot(df_1d, aes(x = expr, y = time/1e6, fill = expr)) +
  geom_violin() +
  facet_wrap(~n, scales = "free") +
  labs(title = "Comparaison des algorithmes Maximum Subarray 1D",
       x = "Algorithm",
       y = "Temps (ms)") +
  theme_minimal()
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
library(dplyr)
df_1d %>%
  group_by(n, expr) %>%
  summarise(
    min_time = min(time) / 1e6,   # Convert nanoseconds to milliseconds
    q1_time = quantile(time, 0.25) / 1e6,
    median_time = median(time) / 1e6,
    mean_time = mean(time) / 1e6,
    q3_time = quantile(time, 0.75) / 1e6,
    max_time = max(time) / 1e6,
    .groups = "drop"
  )
```


___ 


# Evaluation de la complexité

Les vecteurs de longueurs `vector_n_insertion` et `vector_n_heap` (`n` dans les dataframes) sont choisis sur l'echelle logarithmique afin d'avoir un pas constant sur l'échelle logarithmique en abscisse pour la régression.

On réalise 10 répétitions pour chaque valeur de `n` et pour chaque algorithme. Les barres d'erreur sont placées en "mean +/- sd". 

```{r simu complexite, echo = FALSE, warning=FALSE, message=FALSE}
# Evaluation de la complexité pour Maximum Subarray

library(ggplot2)
library(dplyr)

# Function to run benchmarking with mean and standard deviation
benchmark_sorting <- function(func_name, n_values, nbRep) {
  results <- sapply(n_values, function(n) {
    times <- replicate(nbRep, one.simu.time(n, func = func_name))  # Run simulations
    c(mean_time = mean(times), sd_time = sd(times))  # Return mean & std dev
  })
  
  # Convert results to a data frame
  data.frame(n = n_values, mean_time = results["mean_time",], sd_time = results["sd_time",])
}

# Parameters
nbSimus <- 20
nbRep <- 10

# Benchmark pour l'algorithme naïf
vector_n_naive <- exp(seq(log(5000), log(50000), length.out = nbSimus)) |> round()
res_Naive <- benchmark_subarray("naive_Rcpp", vector_n_naive, nbRep)

# Benchmark pour Kadane
vector_n_kadane <- exp(seq(log(10000), log(500000), length.out = nbSimus)) |> round()
res_Kadane <- benchmark_subarray("opt_Rcpp", vector_n_kadane, nbRep)

# Graphique log-log avec barres d'erreur
ggplot() +
  # Algorithme naïf
  geom_line(data = res_Naive, aes(x = n, y = mean_time, color = "Naïf Rcpp"), size = 1) +
  geom_errorbar(data = res_Naive, 
                aes(x = n, ymin = mean_time - sd_time, ymax = mean_time + sd_time, color = "Naïf Rcpp"), 
                width = 0.1, alpha = 0.5) +
  
  # Algorithme de Kadane
  geom_line(data = res_Kadane, aes(x = n, y = mean_time, color = "Kadane Rcpp"), size = 1) +
  geom_errorbar(data = res_Kadane, 
                aes(x = n, ymin = mean_time - sd_time, ymax = mean_time + sd_time, color = "Kadane Rcpp"), 
                width = 0.1, alpha = 0.5) +

  # Échelles logarithmiques
  scale_x_log10() +
  scale_y_log10() +
  
  # Labels & thème
  labs(title = "Performance des algorithmes Maximum Subarray (échelle log-log)",
       x = "Taille des données (échelle log)", 
       y = "Temps moyen d'exécution (ms, échelle log)",
       color = "Algorithm") +
  theme_minimal()

```

```{r}
# Affichage des résultats
res_Naive
res_Kadane
```

On vérifie la valeur du coefficient directeur pour les deux méthodes:

```{r, echo = FALSE, warning=FALSE, message=FALSE}
# Estimation de la complexité pour l'algorithme naïf
model_naive <- lm(log(res_Naive$mean_time) ~ log(res_Naive$n))
print(summary(model_naive)) 
cat("Exposant estimé (naïf):", coef(model_naive)[2], "\n")
```


```{r, echo = FALSE, warning=FALSE, message=FALSE}
# Estimation de la complexité pour Kadane
model_kadane <- lm(log(res_Kadane$mean_time) ~ log(res_Kadane$n))
print(summary(model_kadane)) 
cat("Exposant estimé (Kadane):", coef(model_kadane)[2], "\n")
```

Les coefficients dfirecteurs trouvés sont bien ceux que l'on attendait. La valeur 2 pour l'insertion et 1 pour le tas.


___ 


# Cas particulier des données presque triées

On considère des données triées avec 5% de valeurs échangées au hasard.

Sur un exemple cela donne : 
```{r}
v <- 1:100
n_swap <- floor(0.05 * length(v))
swap_indices <- sample(length(v), n_swap)
v[swap_indices] <- sample(v[swap_indices])
v
```


```{r}
one.simu2 <- function(n, func)
{
  v <- 1:n
  n_swap <- floor(0.05 * length(v))
  swap_indices <- sample(length(v), n_swap)
  v[swap_indices] <- sample(v[swap_indices])
  if(func == "insertion_sort"){insertion_sort(v)}
  if(func == "heap_sort"){heap_sort(v)} 
  if(func == "insertion_sort_Rcpp"){insertion_sort_Rcpp(v)}
  if(func == "heap_sort_Rcpp"){heap_sort_Rcpp(v)}
}
```


```{r benchmark2, echo = FALSE, warning=FALSE, message=FALSE}
# Function to run benchmark
benchmark_sorting <- function(n, times = 50)
{
  microbenchmark(
    insertion_sort = one.simu2(n, func = "insertion_sort_Rcpp"),
    heap_sort = one.simu2(n, func = "heap_sort_Rcpp"),
    times = times,
    control = list(gc = FALSE)
  )
}
# Run benchmarks for different n values
n_values <- c(1000, 10000)
results <- lapply(n_values, benchmark_sorting)

# Combine results into a single dataframe with n as an identifier
df_results <- do.call(rbind, Map(cbind, results, n = n_values))
# Plot with better aesthetics
ggplot(df_results, aes(x = expr, y = time / 1e6, fill = expr)) +
  geom_violin(alpha = 0.7) +
  facet_wrap(~n, scales = "free") +
  labs(title = "Sorting Algorithm in Rcpp Benchmark",
       x = "Sorting Algorithm",
       y = "Execution Time (ms)",
       fill = "Algorithm") +
  theme_minimal()
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
library(dplyr)
df_results %>%
  group_by(n, expr) %>%
  summarise(
    min_time = min(time) / 1e6,   # Convert nanoseconds to milliseconds
    q1_time = quantile(time, 0.25) / 1e6,
    median_time = median(time) / 1e6,
    mean_time = mean(time) / 1e6,
    q3_time = quantile(time, 0.75) / 1e6,
    max_time = max(time) / 1e6,
    .groups = "drop"
  )
```


L'algorithme d'insertion est ici plus rapide pour la longueur `1000`. Cela est dû au fait que pour un vecteur déjà trié, l'algorithme d'insertion est linéaire et nous sommes dans un cas proche du linéaire.

