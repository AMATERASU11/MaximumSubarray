---
title: | 
  | Analyse de deux algorithmes de tableau maximum par comparaison
author: "Manal Derghal, Khalil Ounis, Taqwa Ben  Romdhane"
date: "lundi 7 avril 2025"
header-includes:
  - \usepackage[french]{babel}
output:
  pdf_document:
    keep_tex: yes
    toc: true
    number_sections: true  
urlcolor: blue
---

---
title: | 
  | Analyse des algorithmes de Maximum Subarray 1D
  |  M2 Data Science Algorithmique 
author:  "Khalil Ounis, Manal Derghal, Taqwa Ben Romdhane"
date: "Lundi 7 avril 2025"
header-includes:
  - \usepackage[french]{babel}
output:
  pdf_document:
    keep_tex: yes
    toc: true
    number_sections: true  
urlcolor: blue
---

\noindent\hrulefill

# Description du problème et objectif

Le problème du Maximum Subarray 1D consiste à trouver la sous-séquence contiguë d'un tableau numérique dont la somme des éléments est maximale. Ce problème classique en algorithmique a des applications en analyse de données financières, bioinformatique et traitement du signal.

[La page Wikipedia du Maximum Subarray](https://en.wikipedia.org/wiki/Maximum_subarray_problem) présente plusieurs approches algorithmiques pour résoudre ce problème. Nous nous concentrons sur deux méthodes :

1.  Algorithme naïf : complexité O(n²)
2.  Algorithme de Kadane : complexité optimale O(n)

Nos objectifs sont :\
a. d'implémenter ces algorithmes en R et C++ et évaluer le gain de temps.\
b. de confirmer les complexités théoriques par des simulations intensives.

------------------------------------------------------------------------

# Un premier exemple

Le package se télécharge ainsi :

```{r, eval=FALSE}
devtools::install_github("AMATERASU11/MaximumSubarray")
```

et ses fonctions sont rendues disponibles sur Rstudio ainsi :

```{r}
library(MaximumSubarray)
```

On simule un petit exemple d'un vecteur `v` de taille `100`

```{r}
set.seed(123)
v <- sample(-100:100, 100, replace = TRUE)
```

On teste les 4 algorithmes implémentés avec des noms explicites :

-   `max_subarray_sum_naive`
-   `max_subarray_sum_opt`
-   `max_subarray_sum_naive_Rcpp`
-   `max_subarray_sum_opt_Rcpp`

Cela donne :

```{r}
v
max_subarray_sum_naive(v)
max_subarray_sum_naive_Rcpp(v)
max_subarray_sum_opt(v)
max_subarray_sum_opt_Rcpp(v)
```

------------------------------------------------------------------------

# Comparaison R avec C++

On va faire des comparaisons pour les deux types d'algorithme en R et C++ pour quantifier leur différence de performance.

La fonction `one.simu.time` retourne le temps recherché, et `one.simu` sera utilisé par `microbenchmark`, on retourne le temps en ms

```{r}
library(microbenchmark)
set.seed(123)

one.simu.time <- function(n, func, data_type = "random") {
  if (data_type == "random") {
    v <- sample(-100:100, n, replace = TRUE)
  } else if (data_type == "all_negative") {
    v <- sample(-100:-1, n, replace = TRUE)
  } else if (data_type == "all_positive") {
    v <- sample(0:100, n, replace = TRUE)
  } else {
    stop("data_type inconnu")
  }

  if (func == "naive") {
    t <- microbenchmark(max_subarray_sum_naive(v), times = 1)$time / 1e6
  } else if (func == "naive_Rcpp") {
    t <- microbenchmark(max_subarray_sum_naive_Rcpp(v), times = 1)$time / 1e6
  } else if (func == "opt") {
    t <- microbenchmark(max_subarray_sum_opt(v), times = 1)$time / 1e6
  } else if (func == "opt_Rcpp") {
    t <- microbenchmark(max_subarray_sum_opt_Rcpp(v), times = 1)$time / 1e6
  } else {
    stop("fonction inconnue")
  }

  return(round(t, 2))
}


```

## Un essai

Sur un exemple, on obtient :

```{r}
set.seed(123)
n <- 10000
one.simu.time(n, func = "naive")
one.simu.time(n, func = "naive_Rcpp")
one.simu.time(n, func = "opt")
one.simu.time(n, func = "opt_Rcpp")
```


## Simulations avec répétitions

On reproduit ces comparaisons de manière plus robuste:

```{r first simu}
set.seed(123)
nbSimus <- 10

time1 <- rep(0, nbSimus); time2 <- rep(0, nbSimus);
time3 <- rep(0, nbSimus); time4 <- rep(0, nbSimus)

for(i in 1:nbSimus){time1[i] <- one.simu.time(n, func = "naive")}
for(i in 1:nbSimus){time2[i] <- one.simu.time(n, func = "naive_Rcpp")}
for(i in 1:nbSimus){time3[i] <- one.simu.time(n, func = "opt")}
for(i in 1:nbSimus){time4[i] <- one.simu.time(n, func = "opt_Rcpp")}
```

Gain C++ versus R

```{r}
naive_speedup_cpp <- mean(time1) / mean(time2)
kadane_speedup_cpp <- mean(time3) / mean(time4)
naive_speedup_cpp
kadane_speedup_cpp
```

Gain naive versus optimisé

```{r}
kadane_vs_naive_R <- mean(time1) / mean(time3)
kadane_vs_naive_Rcpp <- mean(time2) / mean(time4)
kadane_vs_naive_R
kadane_vs_naive_Rcpp
```

On recommence avec `n = 20000` seulement pour le gain avec C++ pour Kadane

```{r second simu}
set.seed(123)
n <- 20000
nbSimus <- 10
time3 <- rep(0, nbSimus); time4 <- rep(0, nbSimus)
for(i in 1:nbSimus){time3[i] <- one.simu.time(n, func = "opt")}
for(i in 1:nbSimus){time4[i] <- one.simu.time(n, func = "opt_Rcpp")}
median_kadane_R_vs_Rcpp <- median(time3) / median(time4)
median_kadane_R_vs_Rcpp
```

**Conclusion:**

### Performances C++ vs R :

-   Naïf : C++ `r round(naive_speedup_cpp)`× plus rapide\
-   Kadane : C++ `r round(kadane_speedup_cpp)`× plus rapide → `r round(median_kadane_R_vs_Rcpp)`× pour n=20k

### Efficacité algorithmique :

-   Kadane `r round(kadane_vs_naive_R)`× mieux que naïf en R\

-   Kadane `r round(kadane_vs_naive_Rcpp)`× mieux que naïf en C++

-   Confirme O(n²) naïf vs O(n) Kadane

### Recommandations :

-   n \> 1k : Toujours préférer Kadane\
-   n \> 10k : Obligatoire d'utiliser Rcpp\
-   Très grands n : Seul Kadane+Rcpp reste viable

## Simulations avec `microbenchmark`

Vous avez besoin des packages `microbenchmark` et `ggplot2` pour exécuter les simulations et afficher les résultats (sous forme de diagrammes en violon). Nous comparons `naive_Rcpp` avec `opt_Rcpp` pour des tailles de données `n = 1000` et `n = 10000`.


```{r benchmark, echo = FALSE, warning=FALSE, message=FALSE}
set.seed(123)

library(microbenchmark)
library(ggplot2)
library(dplyr)

benchmark_1d <- function(n) {
  v <- sample(-100:100, n, replace = TRUE)
  microbenchmark(
    Naif_Cpp = max_subarray_sum_naive_Rcpp(v),
    Kadane_Cpp = max_subarray_sum_opt_Rcpp(v),
    times = 50
  )
}

n_values <- c(100, 5000, 10000)
results_1d <- lapply(n_values, benchmark_1d)

# Visualisation
df_1d <- do.call(rbind, Map(cbind, results_1d, n = n_values))
ggplot(df_1d, aes(x = expr, y = time/1e6, fill = expr)) +
  scale_y_log10() +
  geom_violin() +
  facet_wrap(~n, scales = "free") +
  labs(title = "Comparaison des algorithmes Maximum Subarray 1D",
       x = "Algorithm",
       y = "Temps (ms)") +
  theme_minimal()
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
df_1d %>%
  group_by(n, expr) %>%
  summarise(
    min_time = min(time) / 1e6,   # Convert nanoseconds to milliseconds
    q1_time = quantile(time, 0.25) / 1e6,
    median_time = median(time) / 1e6,
    mean_time = mean(time) / 1e6,
    q3_time = quantile(time, 0.75) / 1e6,
    max_time = max(time) / 1e6,
    .groups = "drop"
  )
```

------------------------------------------------------------------------

# Evaluation de la complexité

Les vecteurs de longueurs `vector_n_naive` et `vector_n_kadane` (`n` dans les dataframes) sont choisis sur l'echelle logarithmique afin d'avoir un pas constant sur l'échelle logarithmique en abscisse pour la régression.

On réalise 10 répétitions pour chaque valeur de `n` et pour chaque algorithme. Les barres d'erreur sont placées en "mean +/- sd".

```{r simu complexite, echo = FALSE, warning=FALSE, message=FALSE}
set.seed(123)

# Function to run benchmarking with mean and standard deviation
benchmark_subarray <- function(func_name, n_values, nbRep) {
  results <- sapply(n_values, function(n) {
    times <- replicate(nbRep, one.simu.time(n, func = func_name))  # Run simulations
    c(mean_time = mean(times), sd_time = sd(times))  # Return mean & std dev
  })
  
  # Convert results to a data frame
  data.frame(n = n_values, mean_time = results["mean_time",], sd_time = results["sd_time",])
}

# Parameters
nbSimus <- 20
nbRep <- 10

# Benchmark pour l'algorithme naïf
vector_n_naive <- exp(seq(log(5000), log(50000), length.out = nbSimus)) |> round()
res_Naive <- benchmark_subarray("naive_Rcpp", vector_n_naive, nbRep)

# Benchmark pour Kadane
vector_n_kadane <- exp(seq(log(400000), log(700000), length.out = nbSimus)) |> round()
res_Kadane <- benchmark_subarray("opt_Rcpp", vector_n_kadane, nbRep)

# Graphique log-log avec barres d'erreur
ggplot() +
  # Algorithme naïf
  geom_line(data = res_Naive, aes(x = n, y = mean_time, color = "Naïf Rcpp"), size = 1) +
  geom_errorbar(data = res_Naive, 
                aes(x = n, ymin = mean_time - sd_time, ymax = mean_time + sd_time, color = "Naïf Rcpp"), 
                width = 0.1, alpha = 0.5) +
  
  # Algorithme de Kadane
  geom_line(data = res_Kadane, aes(x = n, y = mean_time, color = "Kadane Rcpp"), size = 1) +
  geom_errorbar(data = res_Kadane, 
                aes(x = n, ymin = mean_time - sd_time, ymax = mean_time + sd_time, color = "Kadane Rcpp"), 
                width = 0.1, alpha = 0.5) +

  # Échelles logarithmiques
  scale_x_log10() +
  scale_y_log10() +
  
  # Labels & thème
  labs(title = "Performance des algorithmes Maximum Subarray (échelle log-log)",
       x = "Taille des données (échelle log)", 
       y = "Temps moyen d'exécution (ms, échelle log)",
       color = "Algorithm") +
  theme_minimal()

```

```{r}
# Affichage des résultats
res_Naive
res_Kadane
```

On vérifie la valeur du coefficient directeur pour les deux méthodes:

```{r, echo = FALSE, warning=FALSE, message=FALSE}
# Estimation de la complexité pour l'algorithme naïf
model_naive <- lm(log(res_Naive$mean_time) ~ log(res_Naive$n))
print(summary(model_naive)) 
cat("Exposant estimé (naïf):", coef(model_naive)[2], "\n")
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
# Estimation de la complexité pour Kadane
model_kadane <- lm(log(res_Kadane$mean_time) ~ log(res_Kadane$n))
print(summary(model_kadane)) 
cat("Exposant estimé (Kadane):", coef(model_kadane)[2], "\n")
```

Les coefficients directeurs trouvés sont bien ceux que l'on attendait. La valeur 2 pour la méthode naïve et 1 pour l'algorithme de Kadane

------------------------------------------------------------------------

# Cas particulier des données presques triées

On considère des données triées avec 5% de valeurs échangées au hasard.

Sur un exemple cela donne : 
```{r}
v <- 1:100
n_swap <- floor(0.05 * length(v))
swap_indices <- sample(length(v), n_swap)
v[swap_indices] <- sample(v[swap_indices])
v
```


```{r}

# Fonctions de simulation
one.simu <- function(n, func) {
  v <- sample(-100:100, n, replace = TRUE)
  if (func == "naive_Rcpp") return(max_subarray_sum_naive_Rcpp(v))
  if (func == "kadane_Rcpp") return(max_subarray_sum_opt_Rcpp(v))
}

one.simu2 <- function(n, func) {
  v <- 1:n
  n_swap <- floor(0.05 * n)
  swap_indices <- sample(n, n_swap)
  v[swap_indices] <- sample(v[swap_indices])
  if (func == "naive_Rcpp") return(max_subarray_sum_naive_Rcpp(v))
  if (func == "kadane_Rcpp") return(max_subarray_sum_opt_Rcpp(v))
}
```


```{r benchmark2, echo = FALSE, warning=FALSE, message=FALSE}
library(ggplot2)

# Benchmark
benchmark_subarray <- function(n, times = 50) {
  microbenchmark(
    naive_random = one.simu(n, "naive_Rcpp"),
    kadane_random = one.simu(n, "kadane_Rcpp"),
    naive_sorted = one.simu2(n, "naive_Rcpp"),
    kadane_sorted = one.simu2(n, "kadane_Rcpp"),
    times = times
  )
}

# Exécution pour différentes tailles
n_values <- c(1000, 10000)
results <- lapply(n_values, benchmark_subarray)

# Combine results into a single dataframe with n as an identifier
df_results <- do.call(rbind, Map(cbind, results, n = n_values))
# Plot with better aesthetics
ggplot(df_results, aes(x = expr, y = time / 1e6, fill = expr)) +
  geom_violin(alpha = 0.7) +
  scale_y_log10()+
  facet_wrap(~n, scales = "free") +
  labs(title = "Subarray Algorithm in Rcpp Benchmark",
       x = "Subarray Algorithm",
       y = "Execution Time (ms)",
       fill = "Algorithm") +
  theme_minimal()
```

```{r, echo = FALSE, warning=FALSE, message=FALSE}
library(dplyr)
df_results %>%
  group_by(n, expr) %>%
  summarise(
    min_time = min(time) / 1e6,   # Convert nanoseconds to milliseconds
    q1_time = quantile(time, 0.25) / 1e6,
    median_time = median(time) / 1e6,
    mean_time = mean(time) / 1e6,
    q3_time = quantile(time, 0.75) / 1e6,
    max_time = max(time) / 1e6,
    .groups = "drop"
  ) %>%
  mutate(type = ifelse(grepl("sorted", expr), "sorted", "random")) %>%
  mutate(algo = ifelse(grepl("naive", expr), "naive", "kadane"))
```
Pour n = 1000, le temps d'exécution est plus rapide que pour n = 10000. Kadane est toujours plus rapide que Naïf, avec un écart plus important à n = 10000. Lorsque les tableaux sont triés, Naïf et Kadane sont beaucoup plus rapides, avec un écart réduit entre les deux.



